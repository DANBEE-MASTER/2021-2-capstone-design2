{"cells":[{"cell_type":"markdown","metadata":{"id":"jaLpL0jogoOu"},"source":["# 1. Setup"]},{"cell_type":"markdown","metadata":{"id":"9HBgSECOgrfa"},"source":["## 1-1. Library Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9YfRKw77yJJq"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import tensorflow_datasets as tfds\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","import numpy as np\n","import pandas as pd\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":292,"status":"ok","timestamp":1639434299724,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"THeDjXObg3rf","outputId":"f01fe81c-a522-4493-a457-da20c29755ee"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 5225552378609793100\n"," xla_global_id: -1, name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 16154099712\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 17441163879343677567\n"," physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n"," xla_global_id: 416903419]"]},"metadata":{},"execution_count":2}],"source":["from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1639434299724,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"qB9b-_lBDiIJ","outputId":"b937d3d2-8111-448f-9481-b96d87d79c2a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Dec 13 22:24:58 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   37C    P0    34W / 250W |    375MiB / 16280MiB |      1%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13654,"status":"ok","timestamp":1639434313373,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"WXcju0P9xpmb","outputId":"e33dd5c7-2431-4731-af6c-905810880588"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive/')"]},{"cell_type":"markdown","metadata":{"id":"U4j7q7BzdN36"},"source":["## 1-2. Hyperparameter setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HJPI715HyJxf"},"outputs":[],"source":["# Dataset hyperparameters\n","image_size = 128\n","image_channels = 3\n","\n","# Algorithm hyperparameters\n","num_epochs = 100\n","patience_num = 10\n","class_num = 2\n","batch_size = 64  \n","width = 128\n","temperature = 0.1\n","\n","# Stronger augmentations for contrastive, weaker ones for supervised training\n","contrastive_augmentation = {\"min_area\": 0.25, \"brightness\": 0.6, \"jitter\": 0.2}\n","classification_augmentation = {\"min_area\": 0.75, \"brightness\": 0.3, \"jitter\": 0.1}\n","\n","#base_path = ''\n","base_path = 'gdrive/My Drive/Research_1_1_1/'\n","\n","path_data = base_path + 'data_numpy/'\n","path_model_result = base_path + 'model_result/3 - SimCLR_result/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7bUNTD9qkRa3"},"outputs":[],"source":["def createDirectory(name): \n","    try: \n","        if not os.path.exists(name): \n","            os.makedirs(name) \n","    except OSError: \n","        print(\"Error: Failed to create the directory.\")  \n","        \n","createDirectory(path_model_result)"]},{"cell_type":"markdown","metadata":{"id":"jj7VhJc5c8QE"},"source":["# 2. Data Load and Image Check"]},{"cell_type":"markdown","metadata":{"id":"wBiPlu6nhcVr"},"source":["## 2-1. Data Load"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SuWlLq7PyJRx"},"outputs":[],"source":["xTrain_S = np.load(path_data + 'xTrain_S.npy')\n","xValid_S = np.load(path_data + 'xValid_S.npy')\n","xTest_S = np.load(path_data + 'xTest_S.npy')\n","\n","yTrain_S = np.load(path_data + 'yTrain_S.npy')\n","yValid_S = np.load(path_data + 'yValid_S.npy')\n","yTest_S = np.load(path_data + 'yTest_S.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1639434321313,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"tTr4OpJSZqu_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6fa71f2b-d832-4071-9d22-bc0b93f848e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["(1920, 128, 128, 3) (1920, 1)\n","(640, 128, 128, 3) (640, 1)\n","(640, 128, 128, 3) (640, 1)\n"]}],"source":["print(xTrain_S.shape, yTrain_S.shape)\n","print(xValid_S.shape, yValid_S.shape)\n","print(xTest_S.shape, yTest_S.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6yoHL9ZbyJbN"},"outputs":[],"source":["xTrain_S = xTrain_S.astype('float32')/255\n","xValid_S = xValid_S.astype('float32')/255\n","xTest_S = xTest_S.astype('float32')/255"]},{"cell_type":"markdown","metadata":{"id":"7mg9s2PEdVds"},"source":["## 2-2. Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sEDiwHK7yJ1s"},"outputs":[],"source":["labeled_train_data = tf.data.Dataset.from_tensor_slices((xTrain_S, yTrain_S))\n","unlabeled_train_data = tf.data.Dataset.from_tensor_slices((xValid_S, yValid_S))\n","test_data = tf.data.Dataset.from_tensor_slices((xTest_S, yTest_S))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U1j6JVuayJ3z"},"outputs":[],"source":["labeled_train_dataset = labeled_train_data.batch(batch_size)\n","unlabeled_train_dataset = unlabeled_train_data.batch(batch_size)\n","test_dataset = test_data.batch(batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EuZphziGyJ6C"},"outputs":[],"source":["train_dataset = tf.data.Dataset.zip(\n","        (unlabeled_train_dataset, labeled_train_dataset)\n","    ).prefetch(buffer_size=tf.data.AUTOTUNE)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1639434321987,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"5zu9nHBYyJ7-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"401a7f6b-ddf4-4c17-bff5-35b4a26d2bc3"},"outputs":[{"output_type":"stream","name":"stdout","text":["labeled_train_dataset :  <BatchDataset shapes: ((None, 128, 128, 3), (None, 1)), types: (tf.float32, tf.int32)>\n","labeled_train_dataset 총 batch_size 세트 :  30\n","unlabeled_train_dataset :  <BatchDataset shapes: ((None, 128, 128, 3), (None, 1)), types: (tf.float32, tf.int32)>\n","unlabeled_train_dataset 총 batch_size 세트 :  10\n","test_dataset :  <BatchDataset shapes: ((None, 128, 128, 3), (None, 1)), types: (tf.float32, tf.int32)>\n","test_dataset 총 batch_size 세트 :  10\n","train_dataset :  <PrefetchDataset shapes: (((None, 128, 128, 3), (None, 1)), ((None, 128, 128, 3), (None, 1))), types: ((tf.float32, tf.int32), (tf.float32, tf.int32))>\n","train_dataset 총 batch_size 세트 :  10\n"]}],"source":["print ('labeled_train_dataset : ' , labeled_train_dataset)\n","print ('labeled_train_dataset 총 batch_size 세트 : ' , len(labeled_train_dataset))\n","print ('unlabeled_train_dataset : ' , unlabeled_train_dataset)\n","print ('unlabeled_train_dataset 총 batch_size 세트 : ' , len(unlabeled_train_dataset))\n","print ('test_dataset : ' , test_dataset)\n","print ('test_dataset 총 batch_size 세트 : ' , len(test_dataset)) \n","print ('train_dataset : ' , train_dataset)\n","print ('train_dataset 총 batch_size 세트 : ' , len(train_dataset)) "]},{"cell_type":"markdown","metadata":{"id":"nZ8oy1zadhi5"},"source":["## 2-3. Image augmentations and visualize_augmentations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fqCxRxaazixX"},"outputs":[],"source":["from tensorflow.keras.layers.experimental import preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GXOC6Vd4ziz7"},"outputs":[],"source":["# Distorts the color distibutions of images\n","class RandomColorAffine(layers.Layer):\n","    def __init__(self, brightness=0, jitter=0, **kwargs):\n","        super().__init__(**kwargs)\n","\n","        self.brightness = brightness\n","        self.jitter = jitter\n","\n","    def call(self, images, training=True):\n","        if training:\n","            batch_size = tf.shape(images)[0]\n","\n","            # Same for all colors\n","            brightness_scales = 1 + tf.random.uniform(\n","                (batch_size, 1, 1, 1), minval=-self.brightness, maxval=self.brightness\n","            )\n","            # Different for all colors\n","            jitter_matrices = tf.random.uniform(\n","                (batch_size, 1, 3, 3), minval=-self.jitter, maxval=self.jitter\n","            )\n","\n","            color_transforms = (\n","                tf.eye(3, batch_shape=[batch_size, 1]) * brightness_scales\n","                + jitter_matrices\n","            )\n","            images = tf.clip_by_value(tf.matmul(images, color_transforms), 0, 1)\n","        return images\n","\n","\n","# Image augmentation module\n","def get_augmenter(min_area, brightness, jitter):\n","    zoom_factor = 1.0 - tf.sqrt(min_area)\n","    return tf.keras.Sequential(\n","        [\n","            tf.keras.Input(shape=(image_size, image_size, image_channels)),\n","            #tf.keras.layers.experimental.preprocessing.Rescaling(1 / 255),\n","            tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n","            tf.keras.layers.experimental.preprocessing.RandomTranslation(zoom_factor / 2, zoom_factor / 2),\n","            tf.keras.layers.experimental.preprocessing.RandomZoom((-zoom_factor, 0.0), (-zoom_factor, 0.0)),\n","            RandomColorAffine(brightness, jitter),\n","        ]\n","    )\n","\n","\n","def visualize_augmentations(num_images):\n","    # Sample a batch from a dataset\n","    images = next(iter(train_dataset))[0][0][:num_images]\n","    # Apply augmentations\n","    augmented_images = zip(\n","        (images),\n","        #tf.keras.layers.experimental.preprocessing.Rescaling(1 / 255)(images),\n","        get_augmenter(**classification_augmentation)(images),\n","        get_augmenter(**contrastive_augmentation)(images),\n","        get_augmenter(**contrastive_augmentation)(images),\n","    )\n","    row_titles = [\n","        \"Original:\",\n","        \"Weakly augmented:\",\n","        \"Strongly augmented:\",\n","        \"Strongly augmented:\",\n","    ]\n","    plt.figure(figsize=(num_images * 2.2, 4 * 2.2), dpi=100)\n","    for column, image_row in enumerate(augmented_images):\n","        for row, image in enumerate(image_row):\n","            plt.subplot(4, num_images, row * num_images + column + 1)\n","            plt.imshow(image)\n","            if column == 0:\n","                plt.title(row_titles[row], loc=\"left\")\n","            plt.axis(\"off\")\n","    plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6702,"status":"ok","timestamp":1639434328686,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"-mV9mUjAzi38","colab":{"base_uri":"https://localhost:8080/","height":613},"outputId":"5b3e850b-10e0-4231-cb9a-a2a9b917195a"},"outputs":[],"source":["visualize_augmentations(num_images=8)"]},{"cell_type":"markdown","metadata":{"id":"XcfJAPHxh1Bb"},"source":["# 3. Network"]},{"cell_type":"markdown","metadata":{"id":"jLH25trMdyhK"},"source":["## 3-1. Encoder architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wtCNzFp2zn-T"},"outputs":[],"source":["def get_encoder():\n","    base_model = tf.keras.applications.Xception(\n","    weights='imagenet',\n","    include_top=False,\n","    pooling='avg')\n","    \n","    model = keras.Sequential([\n","    base_model,\n","    layers.Dense(width, activation=\"relu\"),\n","    ])\n","    \n","    return model"]},{"cell_type":"markdown","metadata":{"id":"gLxBwtnUuq3u"},"source":["## 3-2. Supervised baseline model - original image"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":416,"status":"ok","timestamp":1639434329099,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"0seUDcCQuslj","colab":{"base_uri":"https://localhost:8080/"},"outputId":"666272f1-7d52-4718-d9f5-074d9af43db9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 0s 0us/step\n","83697664/83683744 [==============================] - 0s 0us/step\n","Model: \"baseline_model_original_image\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential_3 (Sequential)   (None, 128)               21123752  \n","                                                                 \n"," dense_1 (Dense)             (None, 128)               16512     \n","                                                                 \n"," dense_2 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_3 (Dense)             (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 21,148,650\n","Trainable params: 21,094,122\n","Non-trainable params: 54,528\n","_________________________________________________________________\n"]}],"source":["# Baseline supervised training with random initialization\n","baseline_model_original_image = keras.Sequential(\n","    [\n","        keras.Input(shape=(image_size, image_size, image_channels)),\n","        #get_augmenter(**classification_augmentation),\n","        get_encoder(),\n","        layers.Dense(128, activation='relu'),\n","        layers.Dense(64, activation='relu'),\n","        layers.Dense(class_num, activation='softmax'),\n","    ],\n","    name=\"baseline_model_original_image\",\n",")\n","\n","baseline_model_original_image.summary()\n","\n","baseline_model_original_image.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":170956,"status":"ok","timestamp":1639434500052,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"c1nOnrgcvyzQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"235bb64d-d9fd-4610-c2d0-a03e57cb2483"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["30/30 [==============================] - 20s 288ms/step - loss: 0.2123 - acc: 0.9099 - val_loss: 7.4894 - val_acc: 0.6656\n","Epoch 2/100\n","30/30 [==============================] - 8s 260ms/step - loss: 0.0548 - acc: 0.9865 - val_loss: 6.6647 - val_acc: 0.7375\n","Epoch 3/100\n","30/30 [==============================] - 8s 259ms/step - loss: 0.0239 - acc: 0.9906 - val_loss: 5.5936 - val_acc: 0.7734\n","Epoch 4/100\n","30/30 [==============================] - 8s 260ms/step - loss: 0.0183 - acc: 0.9932 - val_loss: 2.6698 - val_acc: 0.8656\n","Epoch 5/100\n","30/30 [==============================] - 8s 257ms/step - loss: 0.0137 - acc: 0.9948 - val_loss: 12.4150 - val_acc: 0.6750\n","Epoch 6/100\n","30/30 [==============================] - 8s 260ms/step - loss: 0.0269 - acc: 0.9911 - val_loss: 0.4655 - val_acc: 0.9344\n","Epoch 7/100\n","30/30 [==============================] - 8s 256ms/step - loss: 0.0296 - acc: 0.9911 - val_loss: 2.9600 - val_acc: 0.8016\n","Epoch 8/100\n","30/30 [==============================] - 8s 257ms/step - loss: 0.0195 - acc: 0.9969 - val_loss: 0.5623 - val_acc: 0.9250\n","Epoch 9/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0244 - acc: 0.9922 - val_loss: 0.0929 - val_acc: 0.9812\n","Epoch 10/100\n","30/30 [==============================] - 8s 260ms/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0708 - val_acc: 0.9906\n","Epoch 11/100\n","30/30 [==============================] - 8s 257ms/step - loss: 7.7912e-04 - acc: 1.0000 - val_loss: 0.0803 - val_acc: 0.9828\n","Epoch 12/100\n","30/30 [==============================] - 8s 258ms/step - loss: 1.7154e-05 - acc: 1.0000 - val_loss: 0.0721 - val_acc: 0.9844\n","Epoch 13/100\n","30/30 [==============================] - 8s 258ms/step - loss: 1.1798e-05 - acc: 1.0000 - val_loss: 0.0655 - val_acc: 0.9875\n","Epoch 14/100\n","30/30 [==============================] - 8s 258ms/step - loss: 9.4875e-06 - acc: 1.0000 - val_loss: 0.0615 - val_acc: 0.9891\n","Epoch 15/100\n","30/30 [==============================] - 8s 257ms/step - loss: 7.9546e-06 - acc: 1.0000 - val_loss: 0.0594 - val_acc: 0.9891\n","Epoch 16/100\n","30/30 [==============================] - 8s 257ms/step - loss: 6.8255e-06 - acc: 1.0000 - val_loss: 0.0579 - val_acc: 0.9891\n","Epoch 17/100\n","30/30 [==============================] - 8s 258ms/step - loss: 5.9557e-06 - acc: 1.0000 - val_loss: 0.0570 - val_acc: 0.9891\n","Epoch 18/100\n","30/30 [==============================] - 8s 257ms/step - loss: 5.2626e-06 - acc: 1.0000 - val_loss: 0.0563 - val_acc: 0.9891\n","Epoch 19/100\n","30/30 [==============================] - 8s 258ms/step - loss: 4.6961e-06 - acc: 1.0000 - val_loss: 0.0560 - val_acc: 0.9891\n","Epoch 20/100\n","30/30 [==============================] - ETA: 0s - loss: 4.2250e-06 - acc: 1.0000Restoring model weights from the end of the best epoch: 10.\n","30/30 [==============================] - 8s 261ms/step - loss: 4.2250e-06 - acc: 1.0000 - val_loss: 0.0558 - val_acc: 0.9891\n","Epoch 00020: early stopping\n","Maximal validation accuracy: 99.06%\n"]}],"source":["ES = EarlyStopping(monitor='val_acc', verbose=1, patience=patience_num, restore_best_weights=True)\n","\n","baseline_model_original_image_history = baseline_model_original_image.fit(\n","    labeled_train_dataset, epochs=num_epochs, validation_data=test_dataset, callbacks=[ES]\n",")\n","print(\n","    \"Maximal validation accuracy: {:.2f}%\".format(\n","        max(baseline_model_original_image_history.history[\"val_acc\"]) * 100\n","    )\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1639434500053,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"ST0GmyO9cTjr","colab":{"base_uri":"https://localhost:8080/","height":677},"outputId":"61e5fa15-3d51-4376-d6aa-5d5ae3038242"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>val_loss</th>\n","      <th>val_acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.212265</td>\n","      <td>0.909896</td>\n","      <td>7.489417</td>\n","      <td>0.665625</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.054835</td>\n","      <td>0.986458</td>\n","      <td>6.664704</td>\n","      <td>0.737500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.023910</td>\n","      <td>0.990625</td>\n","      <td>5.593642</td>\n","      <td>0.773438</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.018326</td>\n","      <td>0.993229</td>\n","      <td>2.669777</td>\n","      <td>0.865625</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.013719</td>\n","      <td>0.994792</td>\n","      <td>12.414951</td>\n","      <td>0.675000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.026884</td>\n","      <td>0.991146</td>\n","      <td>0.465468</td>\n","      <td>0.934375</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.029586</td>\n","      <td>0.991146</td>\n","      <td>2.959956</td>\n","      <td>0.801562</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.019510</td>\n","      <td>0.996875</td>\n","      <td>0.562293</td>\n","      <td>0.925000</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.024356</td>\n","      <td>0.992188</td>\n","      <td>0.092915</td>\n","      <td>0.981250</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.007943</td>\n","      <td>0.997396</td>\n","      <td>0.070767</td>\n","      <td>0.990625</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.000779</td>\n","      <td>1.000000</td>\n","      <td>0.080312</td>\n","      <td>0.982813</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.000017</td>\n","      <td>1.000000</td>\n","      <td>0.072128</td>\n","      <td>0.984375</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.000012</td>\n","      <td>1.000000</td>\n","      <td>0.065543</td>\n","      <td>0.987500</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.000009</td>\n","      <td>1.000000</td>\n","      <td>0.061525</td>\n","      <td>0.989062</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.000008</td>\n","      <td>1.000000</td>\n","      <td>0.059352</td>\n","      <td>0.989062</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.000007</td>\n","      <td>1.000000</td>\n","      <td>0.057933</td>\n","      <td>0.989062</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.000006</td>\n","      <td>1.000000</td>\n","      <td>0.056962</td>\n","      <td>0.989062</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.000005</td>\n","      <td>1.000000</td>\n","      <td>0.056330</td>\n","      <td>0.989062</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.000005</td>\n","      <td>1.000000</td>\n","      <td>0.055951</td>\n","      <td>0.989062</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.000004</td>\n","      <td>1.000000</td>\n","      <td>0.055767</td>\n","      <td>0.989062</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        loss       acc   val_loss   val_acc\n","0   0.212265  0.909896   7.489417  0.665625\n","1   0.054835  0.986458   6.664704  0.737500\n","2   0.023910  0.990625   5.593642  0.773438\n","3   0.018326  0.993229   2.669777  0.865625\n","4   0.013719  0.994792  12.414951  0.675000\n","5   0.026884  0.991146   0.465468  0.934375\n","6   0.029586  0.991146   2.959956  0.801562\n","7   0.019510  0.996875   0.562293  0.925000\n","8   0.024356  0.992188   0.092915  0.981250\n","9   0.007943  0.997396   0.070767  0.990625\n","10  0.000779  1.000000   0.080312  0.982813\n","11  0.000017  1.000000   0.072128  0.984375\n","12  0.000012  1.000000   0.065543  0.987500\n","13  0.000009  1.000000   0.061525  0.989062\n","14  0.000008  1.000000   0.059352  0.989062\n","15  0.000007  1.000000   0.057933  0.989062\n","16  0.000006  1.000000   0.056962  0.989062\n","17  0.000005  1.000000   0.056330  0.989062\n","18  0.000005  1.000000   0.055951  0.989062\n","19  0.000004  1.000000   0.055767  0.989062"]},"metadata":{},"execution_count":20}],"source":["baseline_model_original_image_df = pd.DataFrame(baseline_model_original_image_history.history)\n","baseline_model_original_image_df.to_csv( path_model_result + 'baseline_model_original_image_df.csv' )\n","baseline_model_original_image_df"]},{"cell_type":"markdown","metadata":{"id":"bv6GUSwUuz0N"},"source":["## 3-3. Supervised baseline model - augmenter image"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2072,"status":"ok","timestamp":1639434502115,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"XNSwbxbzzoCp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ebdfe7f7-71f1-4457-b2d4-a05d23fac1d4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"baseline_model_augmenter_image\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential_4 (Sequential)   (None, 128, 128, 3)       0         \n","                                                                 \n"," sequential_5 (Sequential)   (None, 128)               21123752  \n","                                                                 \n"," dense_5 (Dense)             (None, 128)               16512     \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dense_7 (Dense)             (None, 2)                 130       \n","                                                                 \n","=================================================================\n","Total params: 21,148,650\n","Trainable params: 21,094,122\n","Non-trainable params: 54,528\n","_________________________________________________________________\n"]}],"source":["# Baseline supervised training with random initialization\n","baseline_model_augmenter_image = keras.Sequential(\n","    [\n","        keras.Input(shape=(image_size, image_size, image_channels)),\n","        get_augmenter(**classification_augmentation),\n","        get_encoder(),\n","        layers.Dense(128, activation='relu'),\n","        layers.Dense(64, activation='relu'),\n","        layers.Dense(class_num, activation='softmax'),\n","    ],\n","    name=\"baseline_model_augmenter_image\",\n",")\n","\n","baseline_model_augmenter_image.summary()\n","\n","baseline_model_augmenter_image.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":183044,"status":"ok","timestamp":1639434685157,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"NK4Z8PHlzoG-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5a34c7e8-45d8-42ad-dfa0-9d41a65f0cc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n","  return dispatch_target(*args, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["30/30 [==============================] - 13s 292ms/step - loss: 0.3435 - acc: 0.8547 - val_loss: 13.1037 - val_acc: 0.5469\n","Epoch 2/100\n","30/30 [==============================] - 8s 266ms/step - loss: 0.1348 - acc: 0.9547 - val_loss: 4.0434 - val_acc: 0.6875\n","Epoch 3/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0737 - acc: 0.9724 - val_loss: 4.5174 - val_acc: 0.6078\n","Epoch 4/100\n","30/30 [==============================] - 8s 266ms/step - loss: 0.0687 - acc: 0.9812 - val_loss: 1.5380 - val_acc: 0.8813\n","Epoch 5/100\n","30/30 [==============================] - 8s 266ms/step - loss: 0.0404 - acc: 0.9849 - val_loss: 0.4003 - val_acc: 0.9656\n","Epoch 6/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0296 - acc: 0.9901 - val_loss: 0.6310 - val_acc: 0.9312\n","Epoch 7/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0351 - acc: 0.9865 - val_loss: 1.0386 - val_acc: 0.8797\n","Epoch 8/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0608 - acc: 0.9786 - val_loss: 0.3872 - val_acc: 0.9375\n","Epoch 9/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0317 - acc: 0.9885 - val_loss: 1.7703 - val_acc: 0.7937\n","Epoch 10/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0307 - acc: 0.9917 - val_loss: 0.5112 - val_acc: 0.9219\n","Epoch 11/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0236 - acc: 0.9927 - val_loss: 2.5819 - val_acc: 0.7703\n","Epoch 12/100\n","30/30 [==============================] - 8s 265ms/step - loss: 0.0338 - acc: 0.9880 - val_loss: 0.1155 - val_acc: 0.9797\n","Epoch 13/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0262 - acc: 0.9896 - val_loss: 2.4424 - val_acc: 0.8344\n","Epoch 14/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0139 - acc: 0.9964 - val_loss: 0.6882 - val_acc: 0.9156\n","Epoch 15/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0140 - acc: 0.9958 - val_loss: 0.1899 - val_acc: 0.9531\n","Epoch 16/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0121 - acc: 0.9958 - val_loss: 0.6655 - val_acc: 0.9062\n","Epoch 17/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0185 - acc: 0.9937 - val_loss: 0.2745 - val_acc: 0.9594\n","Epoch 18/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0179 - acc: 0.9948 - val_loss: 0.2115 - val_acc: 0.9422\n","Epoch 19/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0376 - acc: 0.9901 - val_loss: 0.2656 - val_acc: 0.9187\n","Epoch 20/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0272 - acc: 0.9922 - val_loss: 0.0893 - val_acc: 0.9719\n","Epoch 21/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0143 - acc: 0.9948 - val_loss: 1.8080 - val_acc: 0.8016\n","Epoch 22/100\n","30/30 [==============================] - ETA: 0s - loss: 0.0132 - acc: 0.9964Restoring model weights from the end of the best epoch: 12.\n","30/30 [==============================] - 8s 267ms/step - loss: 0.0132 - acc: 0.9964 - val_loss: 0.2204 - val_acc: 0.9531\n","Epoch 00022: early stopping\n","Maximal validation accuracy: 97.97%\n"]}],"source":["ES = EarlyStopping(monitor='val_acc', verbose=1, patience=patience_num, restore_best_weights=True)\n","\n","baseline_model_augmenter_image_history = baseline_model_augmenter_image.fit(\n","    labeled_train_dataset, epochs=num_epochs, validation_data=test_dataset, callbacks=[ES]\n",")\n","print(\n","    \"Maximal validation accuracy: {:.2f}%\".format(\n","        max(baseline_model_augmenter_image_history.history[\"val_acc\"]) * 100\n","    )\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1639434685158,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"UPObH7dTdnal","colab":{"base_uri":"https://localhost:8080/","height":739},"outputId":"b7216004-6233-4fbb-e34e-b967f8fe560f"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>val_loss</th>\n","      <th>val_acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.343520</td>\n","      <td>0.854688</td>\n","      <td>13.103740</td>\n","      <td>0.546875</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.134793</td>\n","      <td>0.954687</td>\n","      <td>4.043365</td>\n","      <td>0.687500</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.073727</td>\n","      <td>0.972396</td>\n","      <td>4.517385</td>\n","      <td>0.607813</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.068697</td>\n","      <td>0.981250</td>\n","      <td>1.538033</td>\n","      <td>0.881250</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.040420</td>\n","      <td>0.984896</td>\n","      <td>0.400285</td>\n","      <td>0.965625</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.029618</td>\n","      <td>0.990104</td>\n","      <td>0.631035</td>\n","      <td>0.931250</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.035095</td>\n","      <td>0.986458</td>\n","      <td>1.038574</td>\n","      <td>0.879687</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.060839</td>\n","      <td>0.978646</td>\n","      <td>0.387192</td>\n","      <td>0.937500</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.031737</td>\n","      <td>0.988542</td>\n","      <td>1.770310</td>\n","      <td>0.793750</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.030718</td>\n","      <td>0.991667</td>\n","      <td>0.511242</td>\n","      <td>0.921875</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.023566</td>\n","      <td>0.992708</td>\n","      <td>2.581851</td>\n","      <td>0.770312</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.033762</td>\n","      <td>0.988021</td>\n","      <td>0.115459</td>\n","      <td>0.979688</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.026167</td>\n","      <td>0.989583</td>\n","      <td>2.442411</td>\n","      <td>0.834375</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.013860</td>\n","      <td>0.996354</td>\n","      <td>0.688201</td>\n","      <td>0.915625</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.014022</td>\n","      <td>0.995833</td>\n","      <td>0.189914</td>\n","      <td>0.953125</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.012107</td>\n","      <td>0.995833</td>\n","      <td>0.665512</td>\n","      <td>0.906250</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.018520</td>\n","      <td>0.993750</td>\n","      <td>0.274500</td>\n","      <td>0.959375</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.017891</td>\n","      <td>0.994792</td>\n","      <td>0.211490</td>\n","      <td>0.942187</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.037592</td>\n","      <td>0.990104</td>\n","      <td>0.265598</td>\n","      <td>0.918750</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.027224</td>\n","      <td>0.992188</td>\n","      <td>0.089296</td>\n","      <td>0.971875</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0.014300</td>\n","      <td>0.994792</td>\n","      <td>1.808023</td>\n","      <td>0.801562</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.013222</td>\n","      <td>0.996354</td>\n","      <td>0.220383</td>\n","      <td>0.953125</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        loss       acc   val_loss   val_acc\n","0   0.343520  0.854688  13.103740  0.546875\n","1   0.134793  0.954687   4.043365  0.687500\n","2   0.073727  0.972396   4.517385  0.607813\n","3   0.068697  0.981250   1.538033  0.881250\n","4   0.040420  0.984896   0.400285  0.965625\n","5   0.029618  0.990104   0.631035  0.931250\n","6   0.035095  0.986458   1.038574  0.879687\n","7   0.060839  0.978646   0.387192  0.937500\n","8   0.031737  0.988542   1.770310  0.793750\n","9   0.030718  0.991667   0.511242  0.921875\n","10  0.023566  0.992708   2.581851  0.770312\n","11  0.033762  0.988021   0.115459  0.979688\n","12  0.026167  0.989583   2.442411  0.834375\n","13  0.013860  0.996354   0.688201  0.915625\n","14  0.014022  0.995833   0.189914  0.953125\n","15  0.012107  0.995833   0.665512  0.906250\n","16  0.018520  0.993750   0.274500  0.959375\n","17  0.017891  0.994792   0.211490  0.942187\n","18  0.037592  0.990104   0.265598  0.918750\n","19  0.027224  0.992188   0.089296  0.971875\n","20  0.014300  0.994792   1.808023  0.801562\n","21  0.013222  0.996354   0.220383  0.953125"]},"metadata":{},"execution_count":23}],"source":["baseline_model_augmenter_image_df = pd.DataFrame(baseline_model_augmenter_image_history.history)\n","baseline_model_augmenter_image_df.to_csv( path_model_result + 'baseline_model_augmenter_image_df.csv' )\n","baseline_model_augmenter_image_df"]},{"cell_type":"markdown","metadata":{"id":"sVxTO2stiOa_"},"source":["## 3-4. ContrastiveModel - augmenter image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"18lAL5KTzoJM"},"outputs":[],"source":["# Define the contrastive model with model-subclassing\n","class ContrastiveModel(keras.Model):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.temperature = temperature\n","        self.contrastive_augmenter = get_augmenter(**contrastive_augmentation)\n","        self.classification_augmenter = get_augmenter(**classification_augmentation)\n","        self.encoder = get_encoder()\n","        # Non-linear MLP as projection head\n","        self.projection_head = keras.Sequential(\n","            [\n","                keras.Input(shape=(width,)),\n","                layers.Dense(width, activation=\"relu\"),\n","                layers.Dense(width),\n","            ],\n","            name=\"projection_head\",\n","        )\n","        # Single dense layer for linear probing\n","        self.linear_probe = keras.Sequential(\n","            [layers.Input(shape=(width,)), layers.Dense(class_num)], name=\"linear_probe\"\n","        )\n","\n","        self.encoder.summary()\n","        self.projection_head.summary()\n","        self.linear_probe.summary()\n","\n","    def compile(self, contrastive_optimizer, probe_optimizer, **kwargs):\n","        super().compile(**kwargs)\n","\n","        self.contrastive_optimizer = contrastive_optimizer\n","        self.probe_optimizer = probe_optimizer\n","\n","        # self.contrastive_loss will be defined as a method\n","        self.probe_loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","        self.contrastive_loss_tracker = keras.metrics.Mean(name=\"c_loss\")\n","        self.contrastive_accuracy = keras.metrics.SparseCategoricalAccuracy(\n","            name=\"c_acc\"\n","        )\n","        self.probe_loss_tracker = keras.metrics.Mean(name=\"p_loss\")\n","        self.probe_accuracy = keras.metrics.SparseCategoricalAccuracy(name=\"p_acc\")\n","\n","    @property\n","    def metrics(self):\n","        return [\n","            self.contrastive_loss_tracker,\n","            self.contrastive_accuracy,\n","            self.probe_loss_tracker,\n","            self.probe_accuracy,\n","        ]\n","\n","    def contrastive_loss(self, projections_1, projections_2):\n","        # InfoNCE loss (information noise-contrastive estimation)\n","        # NT-Xent loss (normalized temperature-scaled cross entropy)\n","\n","        # Cosine similarity: the dot product of the l2-normalized feature vectors\n","        projections_1 = tf.math.l2_normalize(projections_1, axis=1)\n","        projections_2 = tf.math.l2_normalize(projections_2, axis=1)\n","        similarities = (\n","            tf.matmul(projections_1, projections_2, transpose_b=True) / self.temperature\n","        )\n","\n","        # The similarity between the representations of two augmented views of the\n","        # same image should be higher than their similarity with other views\n","        batch_size = tf.shape(projections_1)[0]\n","        contrastive_labels = tf.range(batch_size)\n","        self.contrastive_accuracy.update_state(contrastive_labels, similarities)\n","        self.contrastive_accuracy.update_state(\n","            contrastive_labels, tf.transpose(similarities)\n","        )\n","\n","        # The temperature-scaled similarities are used as logits for cross-entropy\n","        # a symmetrized version of the loss is used here\n","        loss_1_2 = keras.losses.sparse_categorical_crossentropy(\n","            contrastive_labels, similarities, from_logits=True\n","        )\n","        loss_2_1 = keras.losses.sparse_categorical_crossentropy(\n","            contrastive_labels, tf.transpose(similarities), from_logits=True\n","        )\n","        return (loss_1_2 + loss_2_1) / 2\n","\n","    def train_step(self, data):\n","        (unlabeled_images, _), (labeled_images, labels) = data\n","\n","        # Both labeled and unlabeled images are used, without labels\n","        images = tf.concat((unlabeled_images, labeled_images), axis=0)\n","        # Each image is augmented twice, differently\n","        augmented_images_1 = self.contrastive_augmenter(images, training=True)\n","        augmented_images_2 = self.contrastive_augmenter(images, training=True)\n","        with tf.GradientTape() as tape:\n","            features_1 = self.encoder(augmented_images_1, training=True)\n","            features_2 = self.encoder(augmented_images_2, training=True)\n","            # The representations are passed through a projection mlp\n","            projections_1 = self.projection_head(features_1, training=True)\n","            projections_2 = self.projection_head(features_2, training=True)\n","            contrastive_loss = self.contrastive_loss(projections_1, projections_2)\n","        gradients = tape.gradient(\n","            contrastive_loss,\n","            self.encoder.trainable_weights + self.projection_head.trainable_weights,\n","        )\n","        self.contrastive_optimizer.apply_gradients(\n","            zip(\n","                gradients,\n","                self.encoder.trainable_weights + self.projection_head.trainable_weights,\n","            )\n","        )\n","        self.contrastive_loss_tracker.update_state(contrastive_loss)\n","\n","        # Labels are only used in evalutation for an on-the-fly logistic regression\n","        preprocessed_images = self.classification_augmenter(\n","            labeled_images, training=True\n","        )\n","        with tf.GradientTape() as tape:\n","            # the encoder is used in inference mode here to avoid regularization\n","            # and updating the batch normalization paramers if they are used\n","            features = self.encoder(preprocessed_images, training=False)\n","            class_logits = self.linear_probe(features, training=True)\n","            probe_loss = self.probe_loss(labels, class_logits)\n","        gradients = tape.gradient(probe_loss, self.linear_probe.trainable_weights)\n","        self.probe_optimizer.apply_gradients(\n","            zip(gradients, self.linear_probe.trainable_weights)\n","        )\n","        self.probe_loss_tracker.update_state(probe_loss)\n","        self.probe_accuracy.update_state(labels, class_logits)\n","\n","        return {m.name: m.result() for m in self.metrics}\n","\n","    def test_step(self, data):\n","        labeled_images, labels = data\n","\n","        # For testing the components are used with a training=False flag\n","        preprocessed_images = self.classification_augmenter(\n","            labeled_images, training=False\n","        )\n","        features = self.encoder(preprocessed_images, training=False)\n","        class_logits = self.linear_probe(features, training=False)\n","        probe_loss = self.probe_loss(labels, class_logits)\n","        self.probe_loss_tracker.update_state(probe_loss)\n","        self.probe_accuracy.update_state(labels, class_logits)\n","\n","        # Only the probe metrics are logged at test time\n","        return {m.name: m.result() for m in self.metrics[2:]}"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":549785,"status":"ok","timestamp":1639435235327,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"1QULc8xYzoLE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b82ac598-3003-423f-e202-e88fe0363579"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," xception (Functional)       (None, 2048)              20861480  \n","                                                                 \n"," dense_8 (Dense)             (None, 128)               262272    \n","                                                                 \n","=================================================================\n","Total params: 21,123,752\n","Trainable params: 21,069,224\n","Non-trainable params: 54,528\n","_________________________________________________________________\n","Model: \"projection_head\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_9 (Dense)             (None, 128)               16512     \n","                                                                 \n"," dense_10 (Dense)            (None, 128)               16512     \n","                                                                 \n","=================================================================\n","Total params: 33,024\n","Trainable params: 33,024\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"linear_probe\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_11 (Dense)            (None, 2)                 258       \n","                                                                 \n","=================================================================\n","Total params: 258\n","Trainable params: 258\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","10/10 [==============================] - 22s 1s/step - c_loss: 4.0314 - c_acc: 0.1223 - p_loss: 1.1038 - p_acc: 0.4844 - val_p_loss: 1.1654 - val_p_acc: 0.5000\n","Epoch 2/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 2.6029 - c_acc: 0.3406 - p_loss: 1.0691 - p_acc: 0.4875 - val_p_loss: 0.9778 - val_p_acc: 0.5312\n","Epoch 3/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 1.9012 - c_acc: 0.4988 - p_loss: 0.8520 - p_acc: 0.4938 - val_p_loss: 0.7930 - val_p_acc: 0.5422\n","Epoch 4/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 1.3800 - c_acc: 0.6395 - p_loss: 0.9012 - p_acc: 0.5000 - val_p_loss: 0.9306 - val_p_acc: 0.5359\n","Epoch 5/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 1.1422 - c_acc: 0.7039 - p_loss: 0.9956 - p_acc: 0.4781 - val_p_loss: 1.0073 - val_p_acc: 0.4547\n","Epoch 6/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.9278 - c_acc: 0.7695 - p_loss: 0.8862 - p_acc: 0.5109 - val_p_loss: 0.8009 - val_p_acc: 0.5719\n","Epoch 7/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.7533 - c_acc: 0.8277 - p_loss: 0.6899 - p_acc: 0.6078 - val_p_loss: 0.6296 - val_p_acc: 0.6781\n","Epoch 8/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.6514 - c_acc: 0.8609 - p_loss: 0.6181 - p_acc: 0.6469 - val_p_loss: 0.6517 - val_p_acc: 0.6859\n","Epoch 9/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.5527 - c_acc: 0.8828 - p_loss: 0.6165 - p_acc: 0.6594 - val_p_loss: 0.6030 - val_p_acc: 0.6812\n","Epoch 10/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.5108 - c_acc: 0.8852 - p_loss: 0.5175 - p_acc: 0.7203 - val_p_loss: 0.5087 - val_p_acc: 0.7609\n","Epoch 11/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.4528 - c_acc: 0.9062 - p_loss: 0.4711 - p_acc: 0.7750 - val_p_loss: 0.4249 - val_p_acc: 0.8031\n","Epoch 12/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.3986 - c_acc: 0.9180 - p_loss: 0.4552 - p_acc: 0.7844 - val_p_loss: 0.4520 - val_p_acc: 0.8031\n","Epoch 13/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.3297 - c_acc: 0.9473 - p_loss: 0.4684 - p_acc: 0.7906 - val_p_loss: 0.4806 - val_p_acc: 0.7734\n","Epoch 14/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.3162 - c_acc: 0.9453 - p_loss: 0.4597 - p_acc: 0.7781 - val_p_loss: 0.4531 - val_p_acc: 0.7812\n","Epoch 15/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.2759 - c_acc: 0.9578 - p_loss: 0.4501 - p_acc: 0.7672 - val_p_loss: 0.3882 - val_p_acc: 0.8359\n","Epoch 16/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.2748 - c_acc: 0.9527 - p_loss: 0.3883 - p_acc: 0.8344 - val_p_loss: 0.3531 - val_p_acc: 0.8703\n","Epoch 17/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.2607 - c_acc: 0.9559 - p_loss: 0.3475 - p_acc: 0.8516 - val_p_loss: 0.3357 - val_p_acc: 0.8594\n","Epoch 18/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.2363 - c_acc: 0.9656 - p_loss: 0.3435 - p_acc: 0.8516 - val_p_loss: 0.3427 - val_p_acc: 0.8750\n","Epoch 19/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.2276 - c_acc: 0.9645 - p_loss: 0.3235 - p_acc: 0.8609 - val_p_loss: 0.3243 - val_p_acc: 0.8703\n","Epoch 20/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.2164 - c_acc: 0.9676 - p_loss: 0.3249 - p_acc: 0.8562 - val_p_loss: 0.3335 - val_p_acc: 0.8687\n","Epoch 21/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.1933 - c_acc: 0.9766 - p_loss: 0.3232 - p_acc: 0.8609 - val_p_loss: 0.3031 - val_p_acc: 0.9000\n","Epoch 22/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.1629 - c_acc: 0.9828 - p_loss: 0.2997 - p_acc: 0.8719 - val_p_loss: 0.2854 - val_p_acc: 0.9000\n","Epoch 23/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.1592 - c_acc: 0.9762 - p_loss: 0.2913 - p_acc: 0.8750 - val_p_loss: 0.2920 - val_p_acc: 0.8953\n","Epoch 24/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.1499 - c_acc: 0.9816 - p_loss: 0.2789 - p_acc: 0.8828 - val_p_loss: 0.2819 - val_p_acc: 0.9016\n","Epoch 25/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.1455 - c_acc: 0.9820 - p_loss: 0.2861 - p_acc: 0.8781 - val_p_loss: 0.2653 - val_p_acc: 0.9156\n","Epoch 26/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.1540 - c_acc: 0.9773 - p_loss: 0.2852 - p_acc: 0.8813 - val_p_loss: 0.2794 - val_p_acc: 0.9156\n","Epoch 27/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.1404 - c_acc: 0.9852 - p_loss: 0.2826 - p_acc: 0.8859 - val_p_loss: 0.2872 - val_p_acc: 0.9156\n","Epoch 28/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.1183 - c_acc: 0.9914 - p_loss: 0.2904 - p_acc: 0.8797 - val_p_loss: 0.2797 - val_p_acc: 0.9016\n","Epoch 29/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.1239 - c_acc: 0.9859 - p_loss: 0.2640 - p_acc: 0.8859 - val_p_loss: 0.2570 - val_p_acc: 0.9047\n","Epoch 30/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.1115 - c_acc: 0.9922 - p_loss: 0.2554 - p_acc: 0.8875 - val_p_loss: 0.2588 - val_p_acc: 0.8938\n","Epoch 31/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.1196 - c_acc: 0.9859 - p_loss: 0.2584 - p_acc: 0.8891 - val_p_loss: 0.2464 - val_p_acc: 0.9047\n","Epoch 32/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.1004 - c_acc: 0.9945 - p_loss: 0.2394 - p_acc: 0.9047 - val_p_loss: 0.2349 - val_p_acc: 0.9172\n","Epoch 33/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0981 - c_acc: 0.9902 - p_loss: 0.2302 - p_acc: 0.9141 - val_p_loss: 0.2249 - val_p_acc: 0.9328\n","Epoch 34/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0924 - c_acc: 0.9930 - p_loss: 0.2312 - p_acc: 0.9000 - val_p_loss: 0.2178 - val_p_acc: 0.9234\n","Epoch 35/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0798 - c_acc: 0.9957 - p_loss: 0.2308 - p_acc: 0.9062 - val_p_loss: 0.2184 - val_p_acc: 0.9266\n","Epoch 36/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0938 - c_acc: 0.9934 - p_loss: 0.2233 - p_acc: 0.9172 - val_p_loss: 0.2201 - val_p_acc: 0.9203\n","Epoch 37/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0856 - c_acc: 0.9937 - p_loss: 0.2294 - p_acc: 0.9078 - val_p_loss: 0.2189 - val_p_acc: 0.9250\n","Epoch 38/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0901 - c_acc: 0.9914 - p_loss: 0.2318 - p_acc: 0.9078 - val_p_loss: 0.2175 - val_p_acc: 0.9312\n","Epoch 39/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0799 - c_acc: 0.9930 - p_loss: 0.2211 - p_acc: 0.9187 - val_p_loss: 0.2144 - val_p_acc: 0.9328\n","Epoch 40/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0778 - c_acc: 0.9937 - p_loss: 0.2244 - p_acc: 0.9094 - val_p_loss: 0.2105 - val_p_acc: 0.9359\n","Epoch 41/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0687 - c_acc: 0.9957 - p_loss: 0.2185 - p_acc: 0.9125 - val_p_loss: 0.2154 - val_p_acc: 0.9250\n","Epoch 42/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0690 - c_acc: 0.9961 - p_loss: 0.2153 - p_acc: 0.9109 - val_p_loss: 0.2060 - val_p_acc: 0.9375\n","Epoch 43/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0710 - c_acc: 0.9937 - p_loss: 0.2084 - p_acc: 0.9047 - val_p_loss: 0.2101 - val_p_acc: 0.9328\n","Epoch 44/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0742 - c_acc: 0.9945 - p_loss: 0.2070 - p_acc: 0.9266 - val_p_loss: 0.2077 - val_p_acc: 0.9359\n","Epoch 45/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0710 - c_acc: 0.9937 - p_loss: 0.2009 - p_acc: 0.9250 - val_p_loss: 0.1984 - val_p_acc: 0.9312\n","Epoch 46/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0701 - c_acc: 0.9934 - p_loss: 0.2082 - p_acc: 0.9156 - val_p_loss: 0.1949 - val_p_acc: 0.9312\n","Epoch 47/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0621 - c_acc: 0.9961 - p_loss: 0.2042 - p_acc: 0.9219 - val_p_loss: 0.2113 - val_p_acc: 0.9312\n","Epoch 48/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0758 - c_acc: 0.9906 - p_loss: 0.2199 - p_acc: 0.9266 - val_p_loss: 0.2177 - val_p_acc: 0.9297\n","Epoch 49/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0679 - c_acc: 0.9961 - p_loss: 0.2221 - p_acc: 0.9125 - val_p_loss: 0.2176 - val_p_acc: 0.9328\n","Epoch 50/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0667 - c_acc: 0.9941 - p_loss: 0.2226 - p_acc: 0.9000 - val_p_loss: 0.2161 - val_p_acc: 0.9281\n","Epoch 51/100\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0777 - c_acc: 0.9891 - p_loss: 0.2174 - p_acc: 0.9125 - val_p_loss: 0.2307 - val_p_acc: 0.9125\n","Epoch 52/100\n","10/10 [==============================] - ETA: 0s - c_loss: 0.0734 - c_acc: 0.9937 - p_loss: 0.2076 - p_acc: 0.9172Restoring model weights from the end of the best epoch: 42.\n","10/10 [==============================] - 10s 1s/step - c_loss: 0.0734 - c_acc: 0.9937 - p_loss: 0.2076 - p_acc: 0.9172 - val_p_loss: 0.2039 - val_p_acc: 0.9281\n","Epoch 00052: early stopping\n","Maximal validation accuracy: 93.75%\n"]}],"source":["ES = EarlyStopping(monitor='val_p_acc', verbose=1, patience=patience_num, restore_best_weights=True)\n","\n","# Contrastive pretraining\n","pretraining_model = ContrastiveModel()\n","pretraining_model.compile(\n","    contrastive_optimizer=keras.optimizers.Adam(),\n","    probe_optimizer=keras.optimizers.Adam(),\n",")\n","\n","pretraining_history = pretraining_model.fit(\n","    train_dataset, epochs=num_epochs, validation_data=test_dataset, callbacks=[ES]\n",")\n","print(\n","    \"Maximal validation accuracy: {:.2f}%\".format(\n","        max(pretraining_history.history[\"val_p_acc\"]) * 100\n","    )\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1639435235328,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"rgATLlYSfBoR","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d72e6efd-d579-460b-b8be-3b398b7be490"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>c_loss</th>\n","      <th>c_acc</th>\n","      <th>p_loss</th>\n","      <th>p_acc</th>\n","      <th>val_p_loss</th>\n","      <th>val_p_acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4.031428</td>\n","      <td>0.122266</td>\n","      <td>1.103794</td>\n","      <td>0.484375</td>\n","      <td>1.165359</td>\n","      <td>0.500000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.602859</td>\n","      <td>0.340625</td>\n","      <td>1.069066</td>\n","      <td>0.487500</td>\n","      <td>0.977846</td>\n","      <td>0.531250</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.901246</td>\n","      <td>0.498828</td>\n","      <td>0.851999</td>\n","      <td>0.493750</td>\n","      <td>0.793010</td>\n","      <td>0.542188</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.380027</td>\n","      <td>0.639453</td>\n","      <td>0.901227</td>\n","      <td>0.500000</td>\n","      <td>0.930598</td>\n","      <td>0.535937</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.142237</td>\n","      <td>0.703906</td>\n","      <td>0.995594</td>\n","      <td>0.478125</td>\n","      <td>1.007257</td>\n","      <td>0.454688</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.927811</td>\n","      <td>0.769531</td>\n","      <td>0.886160</td>\n","      <td>0.510938</td>\n","      <td>0.800876</td>\n","      <td>0.571875</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.753342</td>\n","      <td>0.827734</td>\n","      <td>0.689870</td>\n","      <td>0.607813</td>\n","      <td>0.629643</td>\n","      <td>0.678125</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.651389</td>\n","      <td>0.860937</td>\n","      <td>0.618116</td>\n","      <td>0.646875</td>\n","      <td>0.651654</td>\n","      <td>0.685938</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.552677</td>\n","      <td>0.882812</td>\n","      <td>0.616486</td>\n","      <td>0.659375</td>\n","      <td>0.602950</td>\n","      <td>0.681250</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.510779</td>\n","      <td>0.885156</td>\n","      <td>0.517508</td>\n","      <td>0.720312</td>\n","      <td>0.508706</td>\n","      <td>0.760938</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0.452822</td>\n","      <td>0.906250</td>\n","      <td>0.471070</td>\n","      <td>0.775000</td>\n","      <td>0.424892</td>\n","      <td>0.803125</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0.398626</td>\n","      <td>0.917969</td>\n","      <td>0.455248</td>\n","      <td>0.784375</td>\n","      <td>0.451982</td>\n","      <td>0.803125</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0.329707</td>\n","      <td>0.947266</td>\n","      <td>0.468383</td>\n","      <td>0.790625</td>\n","      <td>0.480586</td>\n","      <td>0.773438</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0.316210</td>\n","      <td>0.945312</td>\n","      <td>0.459733</td>\n","      <td>0.778125</td>\n","      <td>0.453112</td>\n","      <td>0.781250</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>0.275914</td>\n","      <td>0.957812</td>\n","      <td>0.450118</td>\n","      <td>0.767187</td>\n","      <td>0.388244</td>\n","      <td>0.835938</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>0.274842</td>\n","      <td>0.952734</td>\n","      <td>0.388298</td>\n","      <td>0.834375</td>\n","      <td>0.353145</td>\n","      <td>0.870313</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>0.260706</td>\n","      <td>0.955859</td>\n","      <td>0.347468</td>\n","      <td>0.851562</td>\n","      <td>0.335671</td>\n","      <td>0.859375</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>0.236335</td>\n","      <td>0.965625</td>\n","      <td>0.343497</td>\n","      <td>0.851562</td>\n","      <td>0.342700</td>\n","      <td>0.875000</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>0.227577</td>\n","      <td>0.964453</td>\n","      <td>0.323512</td>\n","      <td>0.860937</td>\n","      <td>0.324325</td>\n","      <td>0.870313</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>0.216400</td>\n","      <td>0.967578</td>\n","      <td>0.324942</td>\n","      <td>0.856250</td>\n","      <td>0.333472</td>\n","      <td>0.868750</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>0.193271</td>\n","      <td>0.976562</td>\n","      <td>0.323153</td>\n","      <td>0.860937</td>\n","      <td>0.303103</td>\n","      <td>0.900000</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>0.162899</td>\n","      <td>0.982813</td>\n","      <td>0.299671</td>\n","      <td>0.871875</td>\n","      <td>0.285424</td>\n","      <td>0.900000</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>0.159221</td>\n","      <td>0.976172</td>\n","      <td>0.291268</td>\n","      <td>0.875000</td>\n","      <td>0.292032</td>\n","      <td>0.895312</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>0.149893</td>\n","      <td>0.981641</td>\n","      <td>0.278860</td>\n","      <td>0.882812</td>\n","      <td>0.281900</td>\n","      <td>0.901563</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>0.145547</td>\n","      <td>0.982031</td>\n","      <td>0.286117</td>\n","      <td>0.878125</td>\n","      <td>0.265336</td>\n","      <td>0.915625</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>0.153989</td>\n","      <td>0.977344</td>\n","      <td>0.285241</td>\n","      <td>0.881250</td>\n","      <td>0.279413</td>\n","      <td>0.915625</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>0.140409</td>\n","      <td>0.985156</td>\n","      <td>0.282598</td>\n","      <td>0.885938</td>\n","      <td>0.287220</td>\n","      <td>0.915625</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>0.118286</td>\n","      <td>0.991406</td>\n","      <td>0.290427</td>\n","      <td>0.879687</td>\n","      <td>0.279676</td>\n","      <td>0.901563</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>0.123925</td>\n","      <td>0.985937</td>\n","      <td>0.263989</td>\n","      <td>0.885938</td>\n","      <td>0.256985</td>\n","      <td>0.904688</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>0.111471</td>\n","      <td>0.992188</td>\n","      <td>0.255431</td>\n","      <td>0.887500</td>\n","      <td>0.258811</td>\n","      <td>0.893750</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>0.119596</td>\n","      <td>0.985937</td>\n","      <td>0.258369</td>\n","      <td>0.889063</td>\n","      <td>0.246386</td>\n","      <td>0.904688</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>0.100429</td>\n","      <td>0.994531</td>\n","      <td>0.239448</td>\n","      <td>0.904688</td>\n","      <td>0.234854</td>\n","      <td>0.917188</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>0.098056</td>\n","      <td>0.990234</td>\n","      <td>0.230168</td>\n","      <td>0.914062</td>\n","      <td>0.224869</td>\n","      <td>0.932813</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>0.092406</td>\n","      <td>0.992969</td>\n","      <td>0.231227</td>\n","      <td>0.900000</td>\n","      <td>0.217752</td>\n","      <td>0.923437</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>0.079820</td>\n","      <td>0.995703</td>\n","      <td>0.230847</td>\n","      <td>0.906250</td>\n","      <td>0.218448</td>\n","      <td>0.926562</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>0.093842</td>\n","      <td>0.993359</td>\n","      <td>0.223256</td>\n","      <td>0.917188</td>\n","      <td>0.220108</td>\n","      <td>0.920313</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>0.085584</td>\n","      <td>0.993750</td>\n","      <td>0.229354</td>\n","      <td>0.907812</td>\n","      <td>0.218938</td>\n","      <td>0.925000</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>0.090129</td>\n","      <td>0.991406</td>\n","      <td>0.231833</td>\n","      <td>0.907812</td>\n","      <td>0.217519</td>\n","      <td>0.931250</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>0.079883</td>\n","      <td>0.992969</td>\n","      <td>0.221148</td>\n","      <td>0.918750</td>\n","      <td>0.214423</td>\n","      <td>0.932813</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>0.077819</td>\n","      <td>0.993750</td>\n","      <td>0.224395</td>\n","      <td>0.909375</td>\n","      <td>0.210531</td>\n","      <td>0.935938</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>0.068655</td>\n","      <td>0.995703</td>\n","      <td>0.218507</td>\n","      <td>0.912500</td>\n","      <td>0.215412</td>\n","      <td>0.925000</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>0.069024</td>\n","      <td>0.996094</td>\n","      <td>0.215253</td>\n","      <td>0.910937</td>\n","      <td>0.205960</td>\n","      <td>0.937500</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>0.071047</td>\n","      <td>0.993750</td>\n","      <td>0.208360</td>\n","      <td>0.904688</td>\n","      <td>0.210053</td>\n","      <td>0.932813</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>0.074225</td>\n","      <td>0.994531</td>\n","      <td>0.206994</td>\n","      <td>0.926562</td>\n","      <td>0.207690</td>\n","      <td>0.935938</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>0.071041</td>\n","      <td>0.993750</td>\n","      <td>0.200852</td>\n","      <td>0.925000</td>\n","      <td>0.198446</td>\n","      <td>0.931250</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>0.070116</td>\n","      <td>0.993359</td>\n","      <td>0.208211</td>\n","      <td>0.915625</td>\n","      <td>0.194935</td>\n","      <td>0.931250</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>0.062130</td>\n","      <td>0.996094</td>\n","      <td>0.204155</td>\n","      <td>0.921875</td>\n","      <td>0.211313</td>\n","      <td>0.931250</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>0.075763</td>\n","      <td>0.990625</td>\n","      <td>0.219851</td>\n","      <td>0.926562</td>\n","      <td>0.217747</td>\n","      <td>0.929688</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>0.067922</td>\n","      <td>0.996094</td>\n","      <td>0.222116</td>\n","      <td>0.912500</td>\n","      <td>0.217632</td>\n","      <td>0.932813</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>0.066708</td>\n","      <td>0.994141</td>\n","      <td>0.222638</td>\n","      <td>0.900000</td>\n","      <td>0.216141</td>\n","      <td>0.928125</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>0.077729</td>\n","      <td>0.989062</td>\n","      <td>0.217448</td>\n","      <td>0.912500</td>\n","      <td>0.230666</td>\n","      <td>0.912500</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>0.073361</td>\n","      <td>0.993750</td>\n","      <td>0.207563</td>\n","      <td>0.917188</td>\n","      <td>0.203947</td>\n","      <td>0.928125</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      c_loss     c_acc    p_loss     p_acc  val_p_loss  val_p_acc\n","0   4.031428  0.122266  1.103794  0.484375    1.165359   0.500000\n","1   2.602859  0.340625  1.069066  0.487500    0.977846   0.531250\n","2   1.901246  0.498828  0.851999  0.493750    0.793010   0.542188\n","3   1.380027  0.639453  0.901227  0.500000    0.930598   0.535937\n","4   1.142237  0.703906  0.995594  0.478125    1.007257   0.454688\n","5   0.927811  0.769531  0.886160  0.510938    0.800876   0.571875\n","6   0.753342  0.827734  0.689870  0.607813    0.629643   0.678125\n","7   0.651389  0.860937  0.618116  0.646875    0.651654   0.685938\n","8   0.552677  0.882812  0.616486  0.659375    0.602950   0.681250\n","9   0.510779  0.885156  0.517508  0.720312    0.508706   0.760938\n","10  0.452822  0.906250  0.471070  0.775000    0.424892   0.803125\n","11  0.398626  0.917969  0.455248  0.784375    0.451982   0.803125\n","12  0.329707  0.947266  0.468383  0.790625    0.480586   0.773438\n","13  0.316210  0.945312  0.459733  0.778125    0.453112   0.781250\n","14  0.275914  0.957812  0.450118  0.767187    0.388244   0.835938\n","15  0.274842  0.952734  0.388298  0.834375    0.353145   0.870313\n","16  0.260706  0.955859  0.347468  0.851562    0.335671   0.859375\n","17  0.236335  0.965625  0.343497  0.851562    0.342700   0.875000\n","18  0.227577  0.964453  0.323512  0.860937    0.324325   0.870313\n","19  0.216400  0.967578  0.324942  0.856250    0.333472   0.868750\n","20  0.193271  0.976562  0.323153  0.860937    0.303103   0.900000\n","21  0.162899  0.982813  0.299671  0.871875    0.285424   0.900000\n","22  0.159221  0.976172  0.291268  0.875000    0.292032   0.895312\n","23  0.149893  0.981641  0.278860  0.882812    0.281900   0.901563\n","24  0.145547  0.982031  0.286117  0.878125    0.265336   0.915625\n","25  0.153989  0.977344  0.285241  0.881250    0.279413   0.915625\n","26  0.140409  0.985156  0.282598  0.885938    0.287220   0.915625\n","27  0.118286  0.991406  0.290427  0.879687    0.279676   0.901563\n","28  0.123925  0.985937  0.263989  0.885938    0.256985   0.904688\n","29  0.111471  0.992188  0.255431  0.887500    0.258811   0.893750\n","30  0.119596  0.985937  0.258369  0.889063    0.246386   0.904688\n","31  0.100429  0.994531  0.239448  0.904688    0.234854   0.917188\n","32  0.098056  0.990234  0.230168  0.914062    0.224869   0.932813\n","33  0.092406  0.992969  0.231227  0.900000    0.217752   0.923437\n","34  0.079820  0.995703  0.230847  0.906250    0.218448   0.926562\n","35  0.093842  0.993359  0.223256  0.917188    0.220108   0.920313\n","36  0.085584  0.993750  0.229354  0.907812    0.218938   0.925000\n","37  0.090129  0.991406  0.231833  0.907812    0.217519   0.931250\n","38  0.079883  0.992969  0.221148  0.918750    0.214423   0.932813\n","39  0.077819  0.993750  0.224395  0.909375    0.210531   0.935938\n","40  0.068655  0.995703  0.218507  0.912500    0.215412   0.925000\n","41  0.069024  0.996094  0.215253  0.910937    0.205960   0.937500\n","42  0.071047  0.993750  0.208360  0.904688    0.210053   0.932813\n","43  0.074225  0.994531  0.206994  0.926562    0.207690   0.935938\n","44  0.071041  0.993750  0.200852  0.925000    0.198446   0.931250\n","45  0.070116  0.993359  0.208211  0.915625    0.194935   0.931250\n","46  0.062130  0.996094  0.204155  0.921875    0.211313   0.931250\n","47  0.075763  0.990625  0.219851  0.926562    0.217747   0.929688\n","48  0.067922  0.996094  0.222116  0.912500    0.217632   0.932813\n","49  0.066708  0.994141  0.222638  0.900000    0.216141   0.928125\n","50  0.077729  0.989062  0.217448  0.912500    0.230666   0.912500\n","51  0.073361  0.993750  0.207563  0.917188    0.203947   0.928125"]},"metadata":{},"execution_count":26}],"source":["pretraining_model_df = pd.DataFrame(pretraining_history.history)\n","pretraining_model_df.to_csv( path_model_result + 'pretraining_model_df.csv' )\n","pretraining_model_df"]},{"cell_type":"markdown","metadata":{"id":"jmwiLrVniZJn"},"source":["## 3-5. Finetuning_model - augmenter image"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":808266,"status":"ok","timestamp":1639436043588,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"RMpwTlxEzoO8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"67644851-27c5-4337-fc80-18387ca40ca5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","30/30 [==============================] - 13s 284ms/step - loss: 0.2237 - acc: 0.9115 - val_loss: 0.6812 - val_acc: 0.9234\n","Epoch 2/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.1141 - acc: 0.9604 - val_loss: 2.2713 - val_acc: 0.8328\n","Epoch 3/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0590 - acc: 0.9844 - val_loss: 6.4119 - val_acc: 0.8750\n","Epoch 4/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0494 - acc: 0.9833 - val_loss: 0.3846 - val_acc: 0.9484\n","Epoch 5/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0496 - acc: 0.9839 - val_loss: 2.4443 - val_acc: 0.7672\n","Epoch 6/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0377 - acc: 0.9875 - val_loss: 1.4588 - val_acc: 0.8953\n","Epoch 7/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0337 - acc: 0.9901 - val_loss: 3.0091 - val_acc: 0.8687\n","Epoch 8/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0239 - acc: 0.9906 - val_loss: 0.3610 - val_acc: 0.9250\n","Epoch 9/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0317 - acc: 0.9896 - val_loss: 0.4447 - val_acc: 0.9406\n","Epoch 10/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0380 - acc: 0.9891 - val_loss: 0.2943 - val_acc: 0.9531\n","Epoch 11/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0226 - acc: 0.9917 - val_loss: 0.2453 - val_acc: 0.9516\n","Epoch 12/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0428 - acc: 0.9911 - val_loss: 0.4352 - val_acc: 0.9266\n","Epoch 13/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0248 - acc: 0.9943 - val_loss: 0.1858 - val_acc: 0.9625\n","Epoch 14/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0124 - acc: 0.9969 - val_loss: 0.3990 - val_acc: 0.9438\n","Epoch 15/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0070 - acc: 0.9969 - val_loss: 0.4890 - val_acc: 0.8906\n","Epoch 16/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0168 - acc: 0.9958 - val_loss: 0.6781 - val_acc: 0.8828\n","Epoch 17/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0310 - acc: 0.9906 - val_loss: 2.3186 - val_acc: 0.8719\n","Epoch 18/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0292 - acc: 0.9932 - val_loss: 1.0453 - val_acc: 0.8109\n","Epoch 19/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0132 - acc: 0.9974 - val_loss: 0.1040 - val_acc: 0.9719\n","Epoch 20/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0123 - acc: 0.9948 - val_loss: 0.1075 - val_acc: 0.9672\n","Epoch 21/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0306 - acc: 0.9891 - val_loss: 0.0854 - val_acc: 0.9734\n","Epoch 22/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0209 - acc: 0.9943 - val_loss: 0.1438 - val_acc: 0.9641\n","Epoch 23/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0139 - acc: 0.9953 - val_loss: 0.1424 - val_acc: 0.9578\n","Epoch 24/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0142 - acc: 0.9969 - val_loss: 0.0418 - val_acc: 0.9781\n","Epoch 25/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.2004 - val_acc: 0.9484\n","Epoch 26/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0082 - acc: 0.9979 - val_loss: 1.3209 - val_acc: 0.8062\n","Epoch 27/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0163 - acc: 0.9958 - val_loss: 0.9036 - val_acc: 0.8641\n","Epoch 28/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0076 - acc: 0.9979 - val_loss: 0.5328 - val_acc: 0.9266\n","Epoch 29/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0263 - acc: 0.9922 - val_loss: 4.1320 - val_acc: 0.7016\n","Epoch 30/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0121 - acc: 0.9964 - val_loss: 1.8553 - val_acc: 0.7531\n","Epoch 31/100\n","30/30 [==============================] - 8s 260ms/step - loss: 0.0046 - acc: 0.9984 - val_loss: 0.6834 - val_acc: 0.8719\n","Epoch 32/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0147 - acc: 0.9964 - val_loss: 0.1761 - val_acc: 0.9609\n","Epoch 33/100\n","30/30 [==============================] - 8s 260ms/step - loss: 0.0093 - acc: 0.9979 - val_loss: 0.9894 - val_acc: 0.9062\n","Epoch 34/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0172 - acc: 0.9948 - val_loss: 0.6655 - val_acc: 0.8625\n","Epoch 35/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0113 - acc: 0.9958 - val_loss: 0.0874 - val_acc: 0.9750\n","Epoch 36/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0118 - acc: 0.9958 - val_loss: 0.1668 - val_acc: 0.9656\n","Epoch 37/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 0.1339 - val_acc: 0.9781\n","Epoch 38/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1413 - val_acc: 0.9750\n","Epoch 39/100\n","30/30 [==============================] - 8s 261ms/step - loss: 5.8661e-04 - acc: 1.0000 - val_loss: 0.1181 - val_acc: 0.9797\n","Epoch 40/100\n","30/30 [==============================] - 8s 260ms/step - loss: 1.0010e-04 - acc: 1.0000 - val_loss: 0.1055 - val_acc: 0.9812\n","Epoch 41/100\n","30/30 [==============================] - 8s 261ms/step - loss: 2.0040e-04 - acc: 1.0000 - val_loss: 0.0984 - val_acc: 0.9812\n","Epoch 42/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0087 - acc: 0.9979 - val_loss: 0.1257 - val_acc: 0.9812\n","Epoch 43/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0199 - acc: 0.9937 - val_loss: 0.1103 - val_acc: 0.9750\n","Epoch 44/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0043 - acc: 0.9984 - val_loss: 0.0910 - val_acc: 0.9766\n","Epoch 45/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 0.9766\n","Epoch 46/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0076 - acc: 0.9974 - val_loss: 0.6108 - val_acc: 0.9047\n","Epoch 47/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0270 - acc: 0.9948 - val_loss: 0.6551 - val_acc: 0.8922\n","Epoch 48/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0127 - acc: 0.9964 - val_loss: 0.4302 - val_acc: 0.9062\n","Epoch 49/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0093 - acc: 0.9979 - val_loss: 0.5691 - val_acc: 0.9000\n","Epoch 50/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0321 - acc: 0.9927 - val_loss: 0.8269 - val_acc: 0.8719\n","Epoch 51/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0040 - acc: 0.9995 - val_loss: 0.1604 - val_acc: 0.9719\n","Epoch 52/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0097 - acc: 0.9979 - val_loss: 0.8575 - val_acc: 0.9000\n","Epoch 53/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0412 - acc: 0.9911 - val_loss: 11.6705 - val_acc: 0.5453\n","Epoch 54/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0178 - acc: 0.9953 - val_loss: 2.4738 - val_acc: 0.7219\n","Epoch 55/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0184 - acc: 0.9937 - val_loss: 0.2701 - val_acc: 0.9422\n","Epoch 56/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.1434 - val_acc: 0.9641\n","Epoch 57/100\n","30/30 [==============================] - 8s 260ms/step - loss: 6.9927e-04 - acc: 1.0000 - val_loss: 0.1037 - val_acc: 0.9766\n","Epoch 58/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.1919 - val_acc: 0.9516\n","Epoch 59/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.1812 - val_acc: 0.9641\n","Epoch 60/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0083 - acc: 0.9979 - val_loss: 0.1121 - val_acc: 0.9703\n","Epoch 61/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0052 - acc: 0.9974 - val_loss: 0.1665 - val_acc: 0.9516\n","Epoch 62/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0199 - acc: 0.9943 - val_loss: 0.2304 - val_acc: 0.9422\n","Epoch 63/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.1231 - val_acc: 0.9688\n","Epoch 64/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0525 - val_acc: 0.9859\n","Epoch 65/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0071 - acc: 0.9979 - val_loss: 0.2245 - val_acc: 0.9500\n","Epoch 66/100\n","30/30 [==============================] - 8s 263ms/step - loss: 0.0061 - acc: 0.9979 - val_loss: 0.0944 - val_acc: 0.9734\n","Epoch 67/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0660 - val_acc: 0.9844\n","Epoch 68/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0031 - acc: 0.9995 - val_loss: 0.0658 - val_acc: 0.9828\n","Epoch 69/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0151 - acc: 0.9948 - val_loss: 0.0616 - val_acc: 0.9844\n","Epoch 70/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0084 - acc: 0.9979 - val_loss: 0.0384 - val_acc: 0.9922\n","Epoch 71/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0331 - acc: 0.9937 - val_loss: 1.8230 - val_acc: 0.8453\n","Epoch 72/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0159 - acc: 0.9964 - val_loss: 0.3801 - val_acc: 0.8500\n","Epoch 73/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0138 - acc: 0.9953 - val_loss: 0.2226 - val_acc: 0.9516\n","Epoch 74/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0163 - acc: 0.9969 - val_loss: 0.1537 - val_acc: 0.9609\n","Epoch 75/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0392 - acc: 0.9906 - val_loss: 2.6561 - val_acc: 0.7797\n","Epoch 76/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0144 - acc: 0.9943 - val_loss: 1.9997 - val_acc: 0.7688\n","Epoch 77/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0048 - acc: 0.9995 - val_loss: 0.2386 - val_acc: 0.9609\n","Epoch 78/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0013 - acc: 0.9995 - val_loss: 0.1341 - val_acc: 0.9766\n","Epoch 79/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0081 - acc: 0.9969 - val_loss: 0.0702 - val_acc: 0.9828\n","Epoch 80/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0018 - acc: 0.9990 - val_loss: 0.0412 - val_acc: 0.9906\n","Epoch 81/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.0565 - val_acc: 0.9844\n","Epoch 82/100\n","30/30 [==============================] - 8s 261ms/step - loss: 5.8682e-04 - acc: 1.0000 - val_loss: 0.0579 - val_acc: 0.9844\n","Epoch 83/100\n","30/30 [==============================] - 8s 262ms/step - loss: 3.6452e-04 - acc: 1.0000 - val_loss: 0.0740 - val_acc: 0.9859\n","Epoch 84/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0843 - val_acc: 0.9828\n","Epoch 85/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0066 - acc: 0.9964 - val_loss: 0.1168 - val_acc: 0.9766\n","Epoch 86/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0099 - acc: 0.9974 - val_loss: 0.2336 - val_acc: 0.9594\n","Epoch 87/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0115 - acc: 0.9964 - val_loss: 0.1022 - val_acc: 0.9766\n","Epoch 88/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0054 - acc: 0.9979 - val_loss: 0.1444 - val_acc: 0.9750\n","Epoch 89/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.1540 - val_acc: 0.9656\n","Epoch 90/100\n","30/30 [==============================] - 8s 261ms/step - loss: 5.6316e-04 - acc: 1.0000 - val_loss: 0.4038 - val_acc: 0.9516\n","Epoch 91/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0024 - acc: 0.9995 - val_loss: 0.1366 - val_acc: 0.9750\n","Epoch 92/100\n","30/30 [==============================] - 8s 261ms/step - loss: 5.2357e-04 - acc: 1.0000 - val_loss: 0.0563 - val_acc: 0.9859\n","Epoch 93/100\n","30/30 [==============================] - 8s 261ms/step - loss: 2.5674e-04 - acc: 1.0000 - val_loss: 0.0642 - val_acc: 0.9875\n","Epoch 94/100\n","30/30 [==============================] - 8s 261ms/step - loss: 1.4779e-04 - acc: 1.0000 - val_loss: 0.0632 - val_acc: 0.9859\n","Epoch 95/100\n","30/30 [==============================] - 8s 261ms/step - loss: 1.5452e-04 - acc: 1.0000 - val_loss: 0.0515 - val_acc: 0.9859\n","Epoch 96/100\n","30/30 [==============================] - 8s 261ms/step - loss: 1.0041e-04 - acc: 1.0000 - val_loss: 0.0580 - val_acc: 0.9875\n","Epoch 97/100\n","30/30 [==============================] - 8s 262ms/step - loss: 0.0036 - acc: 0.9984 - val_loss: 0.1466 - val_acc: 0.9781\n","Epoch 98/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0040 - acc: 0.9990 - val_loss: 0.1354 - val_acc: 0.9656\n","Epoch 99/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0068 - acc: 0.9990 - val_loss: 0.0394 - val_acc: 0.9859\n","Epoch 100/100\n","30/30 [==============================] - 8s 261ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0419 - val_acc: 0.9828\n","Maximal validation accuracy: 99.22%\n"]}],"source":["ES = EarlyStopping(monitor='val_p_acc', verbose=1, patience=patience_num, restore_best_weights=True)\n","\n","finetuning_model = keras.Sequential(\n","    [\n","        layers.Input(shape=(image_size, image_size, image_channels)),\n","        get_augmenter(**classification_augmentation),\n","        pretraining_model.encoder,\n","        layers.Dense(class_num),\n","    ],\n","    name=\"finetuning_model\",\n",")\n","finetuning_model.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",")\n","\n","finetuning_history = finetuning_model.fit(\n","    labeled_train_dataset, epochs=num_epochs, validation_data=test_dataset, callbacks=[ES]\n",")\n","print(\n","    \"Maximal validation accuracy: {:.2f}%\".format(\n","        max(finetuning_history.history[\"val_acc\"]) * 100\n","    )\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1639436043589,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"Ns4-YrDWfSQf","colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"b995f88a-8b2f-4ed3-e5fb-35ed31fbb9b5"},"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>loss</th>\n","      <th>acc</th>\n","      <th>val_loss</th>\n","      <th>val_acc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.223744</td>\n","      <td>0.911458</td>\n","      <td>0.681243</td>\n","      <td>0.923437</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.114096</td>\n","      <td>0.960417</td>\n","      <td>2.271286</td>\n","      <td>0.832812</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.058981</td>\n","      <td>0.984375</td>\n","      <td>6.411880</td>\n","      <td>0.875000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.049359</td>\n","      <td>0.983333</td>\n","      <td>0.384612</td>\n","      <td>0.948438</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.049640</td>\n","      <td>0.983854</td>\n","      <td>2.444311</td>\n","      <td>0.767187</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>0.000100</td>\n","      <td>1.000000</td>\n","      <td>0.057962</td>\n","      <td>0.987500</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>0.003559</td>\n","      <td>0.998438</td>\n","      <td>0.146596</td>\n","      <td>0.978125</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>0.004040</td>\n","      <td>0.998958</td>\n","      <td>0.135447</td>\n","      <td>0.965625</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>0.006802</td>\n","      <td>0.998958</td>\n","      <td>0.039387</td>\n","      <td>0.985937</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>0.002134</td>\n","      <td>1.000000</td>\n","      <td>0.041879</td>\n","      <td>0.982813</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 4 columns</p>\n","</div>"],"text/plain":["        loss       acc  val_loss   val_acc\n","0   0.223744  0.911458  0.681243  0.923437\n","1   0.114096  0.960417  2.271286  0.832812\n","2   0.058981  0.984375  6.411880  0.875000\n","3   0.049359  0.983333  0.384612  0.948438\n","4   0.049640  0.983854  2.444311  0.767187\n","..       ...       ...       ...       ...\n","95  0.000100  1.000000  0.057962  0.987500\n","96  0.003559  0.998438  0.146596  0.978125\n","97  0.004040  0.998958  0.135447  0.965625\n","98  0.006802  0.998958  0.039387  0.985937\n","99  0.002134  1.000000  0.041879  0.982813\n","\n","[100 rows x 4 columns]"]},"metadata":{},"execution_count":28}],"source":["finetuning_model_df = pd.DataFrame(finetuning_history.history)\n","finetuning_model_df.to_csv( path_model_result + 'finetuning_model_df.csv' )\n","finetuning_model_df"]},{"cell_type":"markdown","metadata":{"id":"Lfmav9sMfZfw"},"source":["## 4. Result Report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5PpfB6_FzoSr"},"outputs":[],"source":["# The classification accuracies of the baseline and the pretraining + finetuning process:\n","def plot_training_curves(pretraining_history, finetuning_history, baseline_model_augmenter_image_history, baseline_model_original_image_history):\n","    for metric_key, metric_name in zip([\"acc\", \"loss\"], [\"accuracy\", \"loss\"]):\n","        plt.figure(figsize=(8, 5), dpi=100)\n","        plt.plot(\n","            baseline_model_original_image_history.history[f\"val_{metric_key}\"], label=\"original_image baseline\"\n","        )\n","        plt.plot(\n","            baseline_model_augmenter_image_history.history[f\"val_{metric_key}\"], label=\"supervised baseline\"\n","        )\n","        plt.plot(\n","            pretraining_history.history[f\"val_p_{metric_key}\"],\n","            label=\"self-supervised pretraining\",\n","        )\n","        plt.plot(\n","            finetuning_history.history[f\"val_{metric_key}\"],\n","            label=\"supervised finetuning\",\n","        )\n","        plt.legend()\n","        plt.title(f\"Classification {metric_name} during training\")\n","        plt.xlabel(\"epochs\")\n","        plt.ylabel(f\"validation {metric_name}\")\n","\n","plot_training_curves(pretraining_history, finetuning_history, baseline_model_augmenter_image_history, baseline_model_original_image_history)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1639436043590,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"nnnRz7I5zi6J","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6c9b7389-9749-4b5a-a4b4-c72fca86a0f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["99.06250238418579\n","97.9687511920929\n","93.75\n","99.21875\n"]}],"source":["print (max(baseline_model_original_image_history.history[\"val_acc\"]) * 100)\n","print (max(baseline_model_augmenter_image_history.history[\"val_acc\"]) * 100)\n","print (max(pretraining_history.history[\"val_p_acc\"]) * 100)\n","print (max(finetuning_history.history[\"val_acc\"]) * 100)"]},{"cell_type":"markdown","metadata":{"id":"JNOcS5Y9fkES"},"source":["## 5. Model Save "]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":930,"status":"ok","timestamp":1639436044514,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"nDQQQjPeiniw","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7dccc192-fd73-492f-d710-2e0b3eee06a9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"pretraining_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," sequential_8 (Sequential)   (None, 128)               21123752  \n","                                                                 \n","=================================================================\n","Total params: 21,123,752\n","Trainable params: 21,069,224\n","Non-trainable params: 54,528\n","_________________________________________________________________\n"]}],"source":["save_model = keras.Sequential(\n","    [\n","        pretraining_model.encoder,\n","    ],\n","    name=\"pretraining_model\",\n",")\n","\n","save_model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1639436044514,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"},"user_tz":-540},"id":"2r4cWLhGing7","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b4ee009-223b-417d-aa4b-4645567093ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n"]}],"source":["save_model.save( path_model_result + 'pretraining_model_encoder.h5' )"]},{"cell_type":"code","source":["save_model.save( path_model_result + 'pretraining_model_encoder.ckpt' )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QC5jIooI_HPJ","executionInfo":{"status":"ok","timestamp":1639436062961,"user_tz":-540,"elapsed":18453,"user":{"displayName":"오연영","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"00783059429347086342"}},"outputId":"e571d914-3369-4179-f50b-4f3574165259"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: gdrive/My Drive/Research_1_1_1/model_result/3 - SimCLR_model_result - 1/pretraining_model_encoder.ckpt/assets\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  layer_config = serialize_layer_fn(layer)\n","/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  return generic_utils.serialize_keras_object(obj)\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"3 - SimCLR.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}